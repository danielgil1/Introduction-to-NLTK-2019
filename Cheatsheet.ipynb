{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive python (IPython) with Jupyter Notebooks\n",
    "\n",
    "\n",
    "Let's play around with our environment:\n",
    "- Setting up and get ready with [Anaconda - https://www.continuum.io/downloads](https://www.continuum.io/downloads). It's free. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import NLTK library and experimental data\n",
    "```python\n",
    "import nltk\n",
    "from nltk.book import *  \n",
    "texts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring vocabulary:  Useful functions\n",
    "```len(text1)``` gives the number of symbols or 'tokens' in your text. This is the total number of words and items of punctuation.\n",
    "\n",
    "```set(text2)``` gives you a list of all the tokens in the text, without the duplicates.\n",
    "\n",
    "```sorted(text4)``` places items in the list into alphabetical order, with punctuation symbols and capitalised words first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring text - useful methods to search inside text\n",
    "\n",
    "```text1.concordance(\"monstrous\")```  shows you a word in context and is useful if you want to be able to discuss the ways in which a word is used in a text. \n",
    "\n",
    "```text2.similar(...)```  will find words used in similar contexts; it is not looking for synonyms, although the results may include synonyms\n",
    "\n",
    "```text2.common_contexts([..., ...])```  allows us to examine just the contexts that are shared by two or more words, such as monstrous and very. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma\n",
    " \n",
    "```text2.collocations()```  A collocation is a sequence of words that occur together unusually often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring text: Plotting dispersion of words\n",
    "\n",
    "```text1.dispersion_plot(words=['sea','whale'])```\n",
    " A **dispersion plot** that shows where given words occur in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data structures: Texts as Lists of Words\n",
    "Python treats a text as a long list of words.\n",
    "\n",
    "```sent1 = ['Call', 'me', 'Ishmael', '.']```\n",
    " Note we use Square brackets here to define our list\n",
    " \n",
    "```sent1.count('me')```counts the times a particular word is in the list\n",
    "\n",
    "```sent2.append('tomorrow')``` if we want to add a single item to a list\n",
    "sent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Indexing Lists\n",
    "We can navigate this list with the help of indexes. Just as we can find out the number of times a word occurs in a text, we can also find where a word first occurs. We can navigate to different points in a text without restriction, so long as we can describe where we want to be.\n",
    "\n",
    "```text4.index('awaken')``` location of the word\n",
    "\n",
    "```text4[158]``` Get the item in that location \n",
    "\n",
    "```text5[16715:16735]``` Slice the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strings: A useful object to store texts\n",
    "\n",
    "A string is a sequence of characters, you can think of it as a list. For example, we can assign a string to a variable, index a string, and slice a string\n",
    "\n",
    "```' '.join(['I','love', 'NLTK'])``` Join the items of a list with a particular string\n",
    "\n",
    "```'I love python'.split()``` Split the string with a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let computers do the repetitive work: Python Loops\n",
    "\n",
    "Teach the computer how to repeat things. \n",
    "\n",
    "Loop to produce the same result as len('Python')\n",
    "\n",
    "```python\n",
    "length = 0\n",
    "for char in 'Python':\n",
    "    length = length + 1\n",
    "print('There are', length, 'letters in this word'`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frecuency Distributions: Counting for analysis\n",
    "We can use Python's ability to perform statistical analysis of data to do further exploration of vocabulary.\n",
    "```python\n",
    "from nltk.probability import FreqDist \n",
    "fdist1 = FreqDist(text1) # creates the frequency distribution\n",
    "fdist1.most_common(10) # get the most common\n",
    "fdist1['like'] # look for the count of a particular item\n",
    "fdist1.max() # get the max count\n",
    "fdist1.freq('a') # frequency for an item\n",
    "fdist1.plot(50,cumulative=False) # plot the distribution\n",
    "fdist2= FreqDist(len(word) for word in text1) # explore other features of thext\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explore your own text: Accessing a corpus   \n",
    "\n",
    "**Corpus** - Structured set of texts. \n",
    "*Corpora* is the plural of this. Example: A collection of medical journals.\n",
    "\n",
    "Get a text from your hard drive\n",
    "```python\n",
    "import os\n",
    "text_path = 'books/pg1080.txt'\n",
    "path=os.path.join(text_path)\n",
    "file = open(os.path.join(text_path), \"r\", encoding='UTF-8')\n",
    "text = file.read()\n",
    "```\n",
    "\n",
    "Get a text from the web\n",
    "```python\n",
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/cache/epub/1080/pg1080.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf-8-sig')\n",
    "```\n",
    "\n",
    "tokenize\n",
    "```python\n",
    "from nltk import word_tokenize,sent_tokenize,wordpunct_tokenize\n",
    "tokens=wordpunct_tokenize(raw) #use the tokenizer you need\n",
    "my_text=Text(tokens)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "802.6666870117188px",
    "left": "22px",
    "top": "137.6666717529297px",
    "width": "333.9791564941406px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
