{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hangman game: PLAY AGAINST NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ _ _ _ length 11\n",
      "You have 4 attempts remaining.\n",
      "\n",
      "Enter your guess:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is a\n",
      "Good guess: _ _ _ a _ _ _ _ _ _ _\n",
      "You have 4 attempts remaining.\n",
      "\n",
      "Enter your guess:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is c\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "\n",
      "Enter your guess:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is v\n",
      "Sorry, try again.\n",
      "You have 2 attempts remaining.\n",
      "\n",
      "Enter your guess:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is v\n",
      "Already guessed this before.\n",
      "You have 1 attempts remaining.\n",
      "\n",
      "Enter your guess:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess is v\n",
      "Already guessed this before.\n",
      "Out of guesses. The word was metalsmiths\n",
      "\n",
      "YOUR MISTAKES: 4\n",
      "\n",
      "Do you want NLTK to play?:y/n\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ _ _ _ length 11\n",
      "You have 4 attempts remaining.\n",
      "Guess is e\n",
      "Good guess: _ e _ _ _ _ _ _ _ _ _\n",
      "You have 4 attempts remaining.\n",
      "Guess is i\n",
      "Good guess: _ e _ _ _ _ _ i _ _ _\n",
      "You have 4 attempts remaining.\n",
      "Guess is a\n",
      "Good guess: _ e _ a _ _ _ i _ _ _\n",
      "You have 4 attempts remaining.\n",
      "Guess is s\n",
      "Good guess: _ e _ a _ s _ i _ _ s\n",
      "You have 4 attempts remaining.\n",
      "Guess is n\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "Guess is r\n",
      "Sorry, try again.\n",
      "You have 2 attempts remaining.\n",
      "Guess is t\n",
      "Good guess: _ e t a _ s _ i t _ s\n",
      "You have 2 attempts remaining.\n",
      "Guess is o\n",
      "Sorry, try again.\n",
      "You have 1 attempts remaining.\n",
      "Guess is l\n",
      "Good guess: _ e t a l s _ i t _ s\n",
      "You have 1 attempts remaining.\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "Out of guesses. The word was metalsmiths\n",
      "\n",
      "NLTK MISTAKES: 4\n",
      "\n",
      "PRESS ANY KEY TO PLAY AGAIN OR N TO STOP:\n"
     ]
    }
   ],
   "source": [
    "play(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes\n",
    "\n",
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    simple function for manual play\n",
    "    \"\"\"\n",
    "    print('\\nEnter your guess:')\n",
    "    try:\n",
    "        return raw_input().lower().strip() # python 3\n",
    "    except NameError:\n",
    "        return input().lower().strip() # python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import re\n",
    "# get unique word types ocurring in the Brown corpus selecting only words with alpahbetic characters - lowercase\n",
    "brown_words = set([word.lower() for word in brown.words()])\n",
    "words=list(set([word.lower() for word in brown_words if re.match(r'^[a-z]+$',word)]))\n",
    "# split for training and testing sets\n",
    "np.random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def play(att):\n",
    "    attempts=att\n",
    "    while True:\n",
    "        word=random.choice(words)\n",
    "        my_mistakes=hangman(word, human, attempts, True)\n",
    "        print('\\nYOUR MISTAKES:',my_mistakes)\n",
    "        print('\\nDo you want NLTK to play?:y/n')\n",
    "        try:\n",
    "            play_nltk= raw_input().lower().strip() # python 3\n",
    "        except NameError:\n",
    "            play_nltk= input().lower().strip() # python 2\n",
    "        if play_nltk.lower()=='y'  :  \n",
    "            nltk_mistakes=hangman(word, ngram_guesser, attempts, True,lambdas=[0.01]*10)\n",
    "            print('\\nNLTK MISTAKES:',nltk_mistakes)\n",
    "\n",
    "        print('\\nPress any key to play again or n to stop:'.upper())\n",
    "        try:\n",
    "            play= raw_input().lower().strip() # python 3\n",
    "        except NameError:\n",
    "            play= input().lower().strip() # python 2\n",
    "\n",
    "\n",
    "        if (play.lower()=='n'):\n",
    "            break\n",
    "        else:\n",
    "            clear_output()\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "39234\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import re\n",
    "# get unique word types ocurring in the Brown corpus selecting only words with alpahbetic characters - lowercase\n",
    "brown_words = set([word.lower() for word in brown.words()])\n",
    "words=list(set([word.lower() for word in brown_words if re.match(r'^[a-z]+$',word)]))\n",
    "# split for training and testing sets\n",
    "np.random.shuffle(words)\n",
    "test_set=words[0:1000]\n",
    "train_set=words[1000:len(words)]\n",
    "print(len(test_set))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing method using the same input arguments as <human> method and returning a character\n",
    "from string import ascii_lowercase\n",
    "\n",
    "def trivial_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed] # from all letters in alphabet\n",
    "    return np.random.choice(letter_available)\n",
    "            \n",
    "def evaluate_model(guesser,dataset,**guesser_args):\n",
    "    verbose=False\n",
    "    max_mistakes=26\n",
    "    mistakes=0\n",
    "    for word_test in dataset:   \n",
    "        mistakes+=hangman(word_test, guesser, max_mistakes, verbose,**guesser_args)\n",
    "      \n",
    "    avg_mistakes=mistakes/len(dataset)\n",
    "    return avg_mistakes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(evaluate_model(trivial_guesser,test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequencies of characters over all training words\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "## Code based on from WSTA_N11_n-gram_language_models.ipynb\n",
    "\n",
    "\n",
    "def get_unigram_counts(words):\n",
    "    unigram_counts = Counter()\n",
    "    \n",
    "    # collect initial unigram statistics\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "                unigram_counts[letter] += 1\n",
    "\n",
    "                \n",
    "    return unigram_counts\n",
    "\n",
    "## end of copied code\n",
    "\n",
    "unigram_counts=get_unigram_counts(train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Unigram model we need to calculate the probabilites for every character $c_i$:<br/>\n",
    "\n",
    "$P_{unigram}(c_i)=\\frac{count(c_i)}{M}$<br/>\n",
    "where $M$ is the total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.497\n"
     ]
    }
   ],
   "source": [
    "def unigram_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    total_counts = float(sum(unigram_counts.values()))\n",
    "    unigram_probs={}\n",
    "    vocab_size = len(unigram_counts)\n",
    "    # calculate the probability for all letter available\n",
    "    for letter in letter_available:\n",
    "        unigram_probs[letter]=(unigram_counts[letter]+1)/(total_counts+vocab_size) #laplace smoothing\n",
    "    \n",
    "    # get the max probability \n",
    "    letter_choice=max(unigram_probs, key=unigram_probs.get)\n",
    "    return letter_choice\n",
    "\n",
    "        \n",
    "# print the average number of mistakes the unigram method makes over the test set.\n",
    "print(evaluate_model(unigram_guesser,test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Unigram model conditioned we need to calculate the probabilites for every character $c_i$:<br/>\n",
    "\n",
    "$P_{unigram}(c_i|n)=\\frac{count(c_i,n)}{M}$<br/>\n",
    "where $M$ is the total number of characters and $n$ is a fixed lenght for a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement conditioning unigram model on the lengh of the word - different models according the lenght\n",
    "# be careful with unseen lenghts in training\n",
    "# create guessing function using the new model and print performance\n",
    "def get_conditional_unigram_counts(words):    \n",
    "    unigram_lenght_counts=defaultdict(Counter)\n",
    "    total_counts=0.0\n",
    "    \n",
    "    # collect initial unigram statistics\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            unigram_lenght_counts[len(word)][letter] += 1\n",
    "            \n",
    "                \n",
    "    return unigram_lenght_counts\n",
    "\n",
    "unigram_lenght_counts=get_conditional_unigram_counts(train_set)\n",
    "\n",
    "def unigram_conditional_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    total_counts = float(sum(unigram_lenght_counts[len(mask)].values()))\n",
    "    unigram_probs={}\n",
    "    vocab_size = len(unigram_lenght_counts)\n",
    "    # calculate the probability for all letter available\n",
    "    for letter in letter_available:\n",
    "        # if the word len is not in the training set total_counts=0. \n",
    "        if (total_counts!=0):\n",
    "            unigram_probs[letter]=(unigram_lenght_counts[len(mask)][letter]+1)/(total_counts+vocab_size)\n",
    "        else:\n",
    "            # out-of-vocabulary words = 1 / |V|\n",
    "            vocab_size = len(unigram_lenght_counts)\n",
    "            zerogram_prob = (1 / float(vocab_size)) \n",
    "            unigram_probs[letter]=zerogram_prob \n",
    "            \n",
    "            \n",
    "    # get the max probability \n",
    "    letter_choice=max(unigram_probs, key=unigram_probs.get)\n",
    "    return letter_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.481\n"
     ]
    }
   ],
   "source": [
    "# print the average number of mistakes the unigram method makes oert the test set.\n",
    "print(evaluate_model(unigram_conditional_guesser,test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_word(word,n):\n",
    "    start=[]\n",
    "    end=[]\n",
    "    start_index=1\n",
    "    \n",
    "    # padding with sentinent symbols\n",
    "        \n",
    "    while start_index<n:\n",
    "        start.append(\"<s\"+str(start_index)+\">\")\n",
    "        start_index+=1\n",
    "    \n",
    "    end_index=n\n",
    "    while end_index>1:\n",
    "        end.append(\"</s\"+str(end_index-1)+\">\")\n",
    "        end_index-=1\n",
    "    \n",
    "    return start + [l.lower() for l in word] + end\n",
    "\n",
    "def get_ngram_counts(words,n):\n",
    "    ngram_counts = defaultdict(Counter)\n",
    "    \n",
    "    # collect bigram counts\n",
    "    for word in words:\n",
    "        word = convert_word(word,n)\n",
    "        if (n<=len(word)):\n",
    "            n_grams=[word[i:i+n] for i in range(len(word)-(n-1))]\n",
    "            for n_gram in n_grams:\n",
    "                if (n==2):\n",
    "                    ngram_counts[n_gram[0]][n_gram[1]]+=1\n",
    "                elif (n==3):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1])][n_gram[2]]+=1\n",
    "                elif (n==4):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1],n_gram[2])][n_gram[3]]+=1\n",
    "                elif (n==5):\n",
    "                    ngram_counts[(n_gram[0],n_gram[1],n_gram[2],n_gram[3])][n_gram[4]]+=1\n",
    "\n",
    "    return ngram_counts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ngram where n = 2...5.\n",
    "bigram_counts=get_ngram_counts(train_set,2)\n",
    "trigram_counts=get_ngram_counts(train_set,3)\n",
    "fourgram_counts=get_ngram_counts(train_set,4)\n",
    "fivegram_counts=get_ngram_counts(train_set,5)\n",
    "\n",
    "# dictionary for query in the guesser\n",
    "ngram_counts = {1 : unigram_counts,\n",
    "           2 : bigram_counts,\n",
    "           3 : trigram_counts,\n",
    "           4 : fourgram_counts,\n",
    "           5 : fivegram_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_prob(letter,context,n,lambdas):\n",
    "    \n",
    "    \n",
    "    prob=0\n",
    "    \n",
    "    # create tuples to make a query with context\n",
    "    if (n>1):\n",
    "        if (len(context)>1):\n",
    "            conditional=tuple(context)\n",
    "        elif(len(context)==1):\n",
    "            conditional=context[0]\n",
    "        else:\n",
    "            conditional=tuple() # no context at all\n",
    "    \n",
    "            \n",
    "\n",
    "    if (n>4):\n",
    "        \n",
    "        # calculate the fivegram\n",
    "        fivegram_count=ngram_counts[5][conditional][letter]*lambdas[5]\n",
    "        fivegram_total_count=float(sum(ngram_counts[5][conditional].values()))\n",
    "        if fivegram_total_count!=0:\n",
    "            interp_prob_fivegram=fivegram_count/fivegram_total_count\n",
    "        else:\n",
    "            interp_prob_fivegram=0\n",
    "            lambdas[4]+=lambdas[5] #if count is 0 I will give the lambda weight to the next ngram\n",
    "            \n",
    "        prob+=interp_prob_fivegram\n",
    "        \n",
    "    if (n>3):\n",
    "        # calculate the fourgram\n",
    "        fourgram_count=ngram_counts[4][conditional][letter]*lambdas[4]\n",
    "        fourgram_total_count=float(sum(ngram_counts[4][conditional].values()))\n",
    "        if fourgram_total_count!=0:\n",
    "            interp_prob_fourgram=fourgram_count/fourgram_total_count\n",
    "        else:\n",
    "            interp_prob_fourgram=0\n",
    "            lambdas[3]+=lambdas[4] #if count is 0 I will give the lambda weight to the next ngram\n",
    "            \n",
    "        prob+=interp_prob_fourgram\n",
    "    \n",
    "    if (n>2):\n",
    "        # calculate the trigram\n",
    "        trigram_count=ngram_counts[3][conditional][letter]*lambdas[3]\n",
    "        trigram_total_count=float(sum(ngram_counts[3][conditional].values()))\n",
    "        if trigram_total_count!=0:\n",
    "            interp_prob_trigram=trigram_count/trigram_total_count\n",
    "        else:\n",
    "            interp_prob_trigram=0\n",
    "            lambdas[2]+=lambdas[3] #if count is 0 I will give the lambda weight to the next ngram\n",
    "        \n",
    "        prob+=interp_prob_trigram\n",
    "        \n",
    "    if (n>1):\n",
    "        # calculate the bigram\n",
    "        bigram_count=ngram_counts[2][conditional][letter]*lambdas[2]\n",
    "        bigram_total_count=float(sum(ngram_counts[2][conditional].values()))\n",
    "        if bigram_total_count!=0:\n",
    "            interp_prob_bigram=bigram_count/bigram_total_count\n",
    "        else:\n",
    "            interp_prob_bigram=0\n",
    "            lambdas[1]+=lambdas[2] #if count is 0 I will give the lambda weight to the next ngram\n",
    "        \n",
    "        prob+=interp_prob_bigram\n",
    "    \n",
    "    if (n>0):\n",
    "        unigram_count=ngram_counts[1][letter]*lambdas[1]\n",
    "        unigram_total_count=float(sum(ngram_counts[1].values()))\n",
    "        if unigram_total_count!=0:\n",
    "            interp_prob_unigram=(unigram_count)/(unigram_total_count) # not smoothed with laplace like the unigram model       \n",
    "        else:\n",
    "            \n",
    "            # out-of-vocabulary words = 1 / |V|\n",
    "            lambdas[0]+=lambdas[1]\n",
    "            vocab_size = len(unigram_total_count)\n",
    "            interp_prob_unigram = (1 / float(vocab_size)) * lambdas[0]\n",
    "        prob+=interp_prob_unigram\n",
    "        \n",
    "        \n",
    "    return math.log(prob)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_guesser(mask, guessed, **kwargs):\n",
    "    letter_available=[letter for letter in ascii_lowercase if letter not in guessed]\n",
    "    blank_probs={}\n",
    "    letter_probs={}\n",
    "    probs=[]\n",
    "    if kwargs.get('n'):       \n",
    "        n=kwargs.get('n')\n",
    "    else:\n",
    "        n=1\n",
    "        \n",
    "    if kwargs.get('lambdas'):       \n",
    "        lambdas=kwargs.get('lambdas')\n",
    "    else:\n",
    "        lambdas={1:1}\n",
    "    word=convert_word(mask,2)\n",
    "    letter_probs=defaultdict(float)\n",
    "    for i in range(len(word)):\n",
    "        if (word[i]==\"_\"):\n",
    "            context=[]\n",
    "            j=i-1\n",
    "            context_len=1\n",
    "            while word[j]!=\"_\" and j>=0 and context_len<n:\n",
    "                context.insert(0,word[j])\n",
    "                j-=1\n",
    "                context_len+=1\n",
    "            \n",
    "            for letter in letter_available:\n",
    "                probability=get_ngram_prob(letter,context.copy(),n,lambdas.copy())\n",
    "                letter_probs[letter]+=probability\n",
    "                \n",
    "              \n",
    "    letter_choice=max(letter_probs, key=letter_probs.get)\n",
    "    return letter_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
